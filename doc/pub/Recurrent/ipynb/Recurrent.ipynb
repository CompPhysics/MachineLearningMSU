{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Data Analysis and Machine Learning: Recurrent neural networks -->\n",
    "# Data Analysis and Machine Learning: Recurrent neural networks\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen at Department of Physics, University of Oslo & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University -->\n",
    "<!-- Author: -->  \n",
    "**Morten Hjorth-Jensen**, Department of Physics, University of Oslo and Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University\n",
    "\n",
    "Date: **Mar 11, 2019**\n",
    "\n",
    "Copyright 1999-2019, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Recurrent neural networks: Overarching view\n",
    "\n",
    "Till now our focus has been, including convolutional neural networks as well, \n",
    "on feedforward neural networks. The output or the\n",
    "activations flow only in one direction, from the input layer to the\n",
    "output layer.\n",
    "\n",
    "A recurrent neural network (RNN) looks very much like a feedforward\n",
    "neural network, except that it also has connections pointing\n",
    "backward. \n",
    "\n",
    "RNNs are used to analyze time series data such as stock prices, and\n",
    "tell you when to buy or sell. In autonomous driving systems, they can\n",
    "anticipate car trajectories and help avoid accidents. More generally,\n",
    "they can work on sequences of arbitrary lengths, rather than on\n",
    "fixed-sized inputs like all the nets we have discussed so far. For\n",
    "example, they can take sentences, documents, or audio samples as\n",
    "input, making them extremely useful for natural language processing\n",
    "systems such as automatic translation and speech-to-text.\n",
    "\n",
    "\n",
    "## Set up of an RNN\n",
    "\n",
    "The figure here displays a simple example of an RNN, with inputs $x_t$\n",
    "at a given time $t$ and outputs $y_t$.  Introducing time as a variable\n",
    "offers an intutitive way of understanding these networks. In addition\n",
    "to the inputs $x_t$, the layer at a time $t$ receives also as input\n",
    "the output from the previous layer $t-1$, that is $y_{t1}$.\n",
    "\n",
    "This means also that we need to have weights that link both the inputs $x_t$ to the outputs $y_t$ as well as weights that link\n",
    "the output from the previous time $y_{t-1}$ and $y_t$.   The figure here shows an example of a simple RNN."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
