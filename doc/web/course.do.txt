TITLE: FRIB-TA Summer School on Machine Learning in Nuclear Experiment and Theory
AUTHOR: "Matthew Hirn":"https://cmse.msu.edu/directory/faculty/matthew-j-hirn/about-me/" at Department of Mathematics and Department of Computational Science, Mathematics and Engineering, Michigan State University, East Lansing, Michigan, USA
AUTHOR: "Morten Hjorth-Jensen":"http://mhjgit.github.io/info/doc/web/" at Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University, East Lansing, Michigan, USA
AUTHOR: "Michelle Kuchera":"https://www.davidson.edu/academics/physics/faculty-and-staff/michelle-kuchera" at Physics Department, Davidson College, Davidson, North Carolina, USA
AUTHOR: "Raghuram Ramanujan":"https://www.davidson.edu/academics/mathematics-and-computer-science/faculty-and-staff/raghuram-ramanujan" at Department of Mathematics and Computer Science, Davidson College, Davidson, North Carolina, USA"

<%
pub_url = 'https://compphysics.github.io/MachineLearningMSU/doc/pub'
published = ['Introduction', 'Regression', 'LogReg', 'GradientOptim', 'DecisionTrees', 'svm', 'NeuralNet',  'CNN', 'RBM', 'Recurrent', 'Autoencoders', 'Reinforce',]
chapters = {
 'Introduction': 'Introduction to Data Analysis and Machine Learning',
 'Regression': 'Regression Methods',
 'LogReg': 'Logistic Regression',
 'GradientOptim': 'Gradient Methods and Optimization',
 'DecisionTrees': 'Decision trees, from simple to random ones',
 'svm': 'Support Vector Machines',
 'NeuralNet': 'Neural Networks',
 'CNN': 'Convolutional Neural Networks',
 'RBM': 'Unsupervised Learning, Boltzmann Machines',
 'Recurrent': 'Recurrent Neural Networks',
 'Autoencoders': 'Autoencoders',
 'Reinforce': 'Reinforcement Learning',
}
%>





<%def name="text_types(name)">

 * LaTeX PDF:
   * For printing:
     * "Standard one-page format": "${pub_url}/${name}/pdf/${name}-minted.pdf"
 * HTML:
   * "Plain html": "${pub_url}/${name}/html/${name}.html"
   * "Bootstrap  slide style, easy for reading on mobile devices": "${pub_url}/${name}/html/${name}-bs.html"
 * Jupyter notebook:
   * "ipynb file": "${pub_url}/${name}/ipynb/${name}.ipynb"
</%def>

<%def name="slide_types(name)">
</%def>



% for ch in published:
===== ${chapters[ch]} =====

${text_types(ch)}

% endfor



===== Python and Scikit Learn, a short guide  =====
 * HTML format only:
   * "Bootstrap  slide style, easy for reading on mobile devices": "http://compphysics.github.io/ComputationalPhysics/doc/pub/learningpython/html/learningpython-bs.html"



===== Practicalities =====
!bblock
o Five lectures per day Monday through Wednesday, starting at 830am, see schedule below
o Hands-on sessions in the afternoons till 6pm
o The last day, Thursday, is dedicated to solving explicit problems with hands-on guidance and relevant examples.
!eblock

=== Recommended textbook ===
!bblock
* Aurelien Geron, Hands‑On Machine Learning with Scikit‑Learn and TensorFlow, O'Reilly
!eblock

!bblock General learning book on statistical analysis:
* Christian Robert and George Casella, Monte Carlo Statistical Methods, Springer
* Peter Hoff, A first course in Bayesian statistical models, Springer
* Trevor Hastie, Robert Tibshirani, Jerome H. Friedman, The Elements of Statistical Learning, Springer
!eblock

!bblock General Machine Learning Books:
* Kevin Murphy, Machine Learning: A Probabilistic Perspective, MIT Press
* Christopher M. Bishop, Pattern Recognition and Machine Learning, Springer
* David J.C. MacKay, Information Theory, Inference, and Learning Algorithms, Cambridge University Press
* David Barber, Bayesian Reasoning and Machine Learning, Cambridge University Press 
!eblock

=== Schedule ===

Lectures are 50 min and there is a small break of 10 min between each lecture. Longer breaks at 1030am-11am and 3pm-330pm.
Acronyms for teachers
* MH = Matthew Hirn
* MHJ = Morten Hjorth-Jensen
* MK = Michelle Kuchera
* RR = Raghuram Ramanujan

_Monday May 20, 2019_:  (breaks of 10 min for every lecture)

* 8am-830am: Welcome and registration
* 830am-930am: Introduction to Machine Learning and various Python packages (MHJ)
* 930am-1030am: Linear Regression (MHJ)
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: Logistic Regression  (MHJ)
* 12pm-1pm: Lunch
* 1pm-2pm: Optimization of functions, gradient descent and stochastic gradient descent (MHJ)
* 2pm-3pm: Decision Trees and Random Forests  (MHJ)
* 3pm-330pm: Break, coffee, tea etc
* 330pm-6pm: Hands-on sessions with selected Physics examples

_Tuesday May 21, 2019_:

* 830am-930am: Neural networks   (MK and RR)
* 930am-1030am: Neural networks and deep learning (MK and RR)
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: Convolutional Neural Networks (CNNs) and examples from nuclear physics experiments (MK and RR)
* 12pm-1pm: Lunch
* 1pm-2pm: CNNs (MK and RR)
* 2pm-3pm: Autoenconders and recurrent neural networks and examples from nuclear physics experiments (MK and RR)
* 3pm-330pm: Break, coffee, tea etc
* 330pm-6pm: Hands-on sessions with examples from nuclear physics experiments

_Wednesday May 22, 2019_:

* 830am-930am: Reinforcement learning (MK and RR)
* 930am-1030am: Introduction to exploratory data analysis and unsupervised learning: PCA (MH)
* 1030am-11am: Break, coffee, tea etc
* 11am-12pm: Clustering and introduction to nonlinear dimension reduction: k-means and t-SNE (MH)
* 12pm-1pm: Lunch
* 1pm-2pm: Nonlinear dimension reduction: Spectral graph theory and manifold learning (MH)
* 2pm-3pm: Boltzmann machines and many-body problems (MHJ)
* 3pm-330pm: Break, coffee, tea etc
* 3pm-6pm: Hands-on sessions with examples from quantum mechanical many-body problems

_Thursday May 23, 2019_:

* 9am-10am: Current state of Machine Learning research (MK)
* 10am-12pm: Hands-on sessions with examples from nuclear physics, experiment and theory
* Coffee, tea etc at 1030am
* 12pm-1pm: Lunch
* 1pm-5pm: Hands-on sessions with examples from nuclear physics, experiment and theory. 
* Coffee, tea, etc at 3pm




