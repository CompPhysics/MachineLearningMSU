{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5UDKqBOW0F8Q"
   },
   "source": [
    "# Further Exploration of AT-TPC Data\n",
    "\n",
    "Now you will have the opportunity to further explore the Argon 46 data from the AT-TPC. This will be a much more open-ended opportunity for you to play with the data and try new things.\n",
    "\n",
    "Before getting started, make sure you are using a GPU-enabled runtime in Google Colab. Go to \"Runtime\" $\\rightarrow$ \"Change runtime type\", then make sure \"GPU\" is selected for \"Hardware accelerator\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSQSsrX90F8S"
   },
   "source": [
    "## Setup\n",
    "\n",
    "This is where you can import any Python libraries that you may want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# This is simply an alias for convenience\n",
    "layers = tf.keras.layers\n",
    "\n",
    "# Prevent TensorFlow from showing us deprecation warnings\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some utility functions that will be helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSQ1yJec0F8w"
   },
   "outputs": [],
   "source": [
    "def get_attpc_class(label):\n",
    "    \"\"\"Gets the class name for a given label.\n",
    "    \n",
    "    Arguments:\n",
    "        label (int): The integer target label.\n",
    "        \n",
    "    Returns:\n",
    "        The name of the class that corresponds to the given label.\n",
    "    \"\"\"\n",
    "    return ['proton', 'carbon', 'junk'][label]\n",
    "\n",
    "def load_attpc_data():\n",
    "    \"\"\"Loads in the AT-TPC data.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of the form ((real_features, real_targets), (simulated_features, simulated_targets))\n",
    "    \"\"\"\n",
    "    simulated_data_origin = 'https://github.com/CompPhysics/MachineLearningMSU/raw/master/Day2_materials/data/simulated-attpc-events.h5'\n",
    "    real_data_origin = 'https://github.com/CompPhysics/MachineLearningMSU/raw/master/Day2_materials/data/real-attpc-events.h5'\n",
    "    \n",
    "    simulated_path = tf.keras.utils.get_file('simulated-attpc-data.h5', origin=simulated_data_origin)\n",
    "    real_path = tf.keras.utils.get_file('real-attpc-data.h5', origin=real_data_origin)\n",
    "    \n",
    "    with h5py.File(simulated_path, 'r') as h5:\n",
    "        simulated_features = h5['features'][:]\n",
    "        simulated_targets = h5['targets'][:]\n",
    "        \n",
    "    with h5py.File(real_path, 'r') as h5:\n",
    "        real_features = h5['features'][:]\n",
    "        real_targets = h5['targets'][:]\n",
    "    \n",
    "    return (real_features, real_targets), (simulated_features, simulated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the AT-TPC data\n",
    "\n",
    "We load in the real and simulated AT-TPC data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(real_features, real_targets), (simulated_features, simulated_targets) = load_attpc_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running this notebook on Google Colab, you will not be able to fit all 50,000 simulated events in RAM after they have been normalized. Run the cell below to use only 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_features = sim_features[:10000]\n",
    "sim_targets = sim_targets[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to proceed\n",
    "\n",
    "We have provided you with the data, and now you can do with it as you wish. Below is a list of suggestions for things you can try, and you can work off of the CNN notebook from the earlier lecture.\n",
    "\n",
    " * Try to improve the results of the transfer learning problem from earlier.\n",
    "   * Perform hyperparameter tuning.\n",
    "   * Train on more of the simulated data.\n",
    "   * Experiment with different network architectures (add dropout, change hidden layers, etc).\n",
    "   * Rather than freezing the convolutional base of the VGG16 model, fine-tune the convolutional layers by training the entire network.\n",
    " * Consider a different learning task: train on real data and test on real data (this should get very good results).\n",
    " * Build and train a CNN from scratch.\n",
    " \n",
    "Model your workflow on the previous CNN notebook. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
